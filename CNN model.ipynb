{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('Final_Dataset_Shuffled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a size for your train set \n",
    "train_size = int(0.7 * len(df))\n",
    "\n",
    "# Split your dataset \n",
    "train_set = df[:train_size]\n",
    "test_set = df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def remove_URL(text):\n",
    "    url=re.sub(\"https?://\\S+|www\\.\\S+\",\" \",str(text))\n",
    "    return url\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.sub(r\"<.*?>\",\" \",str(text))\n",
    "    return html\n",
    "\n",
    "def remove_punct(text):\n",
    "    table=str.maketrans(\"\",\"\",string.punctuation)\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train_set[\"Content\"]=train_set.Content.map(lambda x: remove_URL(x))\n",
    "train_set[\"Content\"]=train_set.Content.map(lambda x: remove_html(x))\n",
    "train_set[\"Content\"]=train_set.Content.map(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ankus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop=set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text=str(text)\n",
    "    text=[word.lower() for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set[\"Content\"]=train_set[\"Content\"].map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        small group peaceful protestors hold signs sho...\n",
       "1        owner beacon hospital denis o’brien believed l...\n",
       "2        according sources close prime minister john ke...\n",
       "3        val demings serving panelist national town hal...\n",
       "4        sun sets behind crude oil pump jack drill pad ...\n",
       "                               ...                        \n",
       "10740    reuters following brief roundup latest scienti...\n",
       "10741    world health organization chief tedros adhanom...\n",
       "10742    president venezuela nicolas maduro speaks pres...\n",
       "10743    new delhi reuters india throw open shopping ma...\n",
       "10744    set two photographs couple woman among injured...\n",
       "Name: Content, Length: 10745, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "\n",
    "lancaster=LancasterStemmer()\n",
    "def lemmatize(text):\n",
    "    final_text=[]\n",
    "    Content_list=[word for word in text.split(' ')]\n",
    "    for word in Content_list:\n",
    "        final_text.append(lancaster.stem(word))\n",
    "    return final_text\n",
    "\n",
    "train_set[\"Content\"]=train_set.Content.map(lambda x: lemmatize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [smal, group, peac, protest, hold, sign, shout...\n",
       "1        [own, beacon, hospit, den, o’brien, believ, lo...\n",
       "2        [accord, sourc, clos, prim, min, john, key, pr...\n",
       "3        [val, dem, serv, panel, nat, town, hal, black,...\n",
       "4        [sun, set, behind, crud, oil, pump, jack, dril...\n",
       "                               ...                        \n",
       "10740    [reut, follow, brief, roundup, latest, sci, st...\n",
       "10741    [world, heal, org, chief, tedro, adhanom, gheb...\n",
       "10742    [presid, venezuel, nicola, maduro, speak, pres...\n",
       "10743    [new, delh, reut, ind, throw, op, shop, mal, r...\n",
       "10744    [set, two, photograph, coupl, wom, among, ind,...\n",
       "Name: Content, Length: 10745, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer=Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_set.Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_content=tokenizer.texts_to_sequences(train_set.Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[473,\n",
       " 150,\n",
       " 854,\n",
       " 81,\n",
       " 393,\n",
       " 161,\n",
       " 1560,\n",
       " 1391,\n",
       " 1156,\n",
       " 519,\n",
       " 862,\n",
       " 844,\n",
       " 18,\n",
       " 1210,\n",
       " 521,\n",
       " 610,\n",
       " 1356,\n",
       " 654,\n",
       " 117,\n",
       " 676,\n",
       " 42,\n",
       " 325,\n",
       " 519,\n",
       " 862,\n",
       " 1516,\n",
       " 81,\n",
       " 258,\n",
       " 3118,\n",
       " 1362,\n",
       " 79,\n",
       " 4,\n",
       " 152,\n",
       " 1139,\n",
       " 403,\n",
       " 161,\n",
       " 18,\n",
       " 1588,\n",
       " 829,\n",
       " 45,\n",
       " 20,\n",
       " 667,\n",
       " 4582,\n",
       " 124,\n",
       " 249,\n",
       " 246,\n",
       " 632,\n",
       " 914,\n",
       " 152,\n",
       " 689,\n",
       " 403,\n",
       " 99,\n",
       " 534,\n",
       " 30,\n",
       " 884,\n",
       " 393,\n",
       " 12,\n",
       " 561,\n",
       " 226,\n",
       " 28,\n",
       " 1588,\n",
       " 3746,\n",
       " 256,\n",
       " 50,\n",
       " 403,\n",
       " 424,\n",
       " 18,\n",
       " 99,\n",
       " 50,\n",
       " 151,\n",
       " 3747,\n",
       " 914,\n",
       " 124,\n",
       " 393,\n",
       " 246,\n",
       " 403,\n",
       " 2534,\n",
       " 18,\n",
       " 226,\n",
       " 99,\n",
       " 914,\n",
       " 478,\n",
       " 4582,\n",
       " 84,\n",
       " 2573,\n",
       " 403,\n",
       " 1402,\n",
       " 2921,\n",
       " 18,\n",
       " 226,\n",
       " 411,\n",
       " 75,\n",
       " 534,\n",
       " 2033,\n",
       " 19,\n",
       " 8,\n",
       " 3,\n",
       " 862,\n",
       " 325,\n",
       " 1193,\n",
       " 4,\n",
       " 8,\n",
       " 57,\n",
       " 48,\n",
       " 141,\n",
       " 123,\n",
       " 914,\n",
       " 3298,\n",
       " 648,\n",
       " 1654,\n",
       " 261,\n",
       " 914,\n",
       " 893,\n",
       " 182,\n",
       " 764,\n",
       " 405,\n",
       " 1504,\n",
       " 22,\n",
       " 171,\n",
       " 408,\n",
       " 2671,\n",
       " 442,\n",
       " 3320,\n",
       " 857,\n",
       " 513,\n",
       " 182,\n",
       " 40,\n",
       " 604,\n",
       " 4,\n",
       " 914,\n",
       " 96,\n",
       " 862,\n",
       " 325,\n",
       " 151,\n",
       " 32,\n",
       " 1159,\n",
       " 18,\n",
       " 1588,\n",
       " 829,\n",
       " 1271,\n",
       " 1061,\n",
       " 4,\n",
       " 56,\n",
       " 753,\n",
       " 68,\n",
       " 4,\n",
       " 71,\n",
       " 820,\n",
       " 914,\n",
       " 1613,\n",
       " 11,\n",
       " 862,\n",
       " 325,\n",
       " 132,\n",
       " 602,\n",
       " 18,\n",
       " 226,\n",
       " 218,\n",
       " 20,\n",
       " 4,\n",
       " 310,\n",
       " 1613,\n",
       " 20,\n",
       " 443,\n",
       " 152,\n",
       " 689,\n",
       " 403,\n",
       " 99,\n",
       " 820,\n",
       " 914,\n",
       " 4986,\n",
       " 40,\n",
       " 81,\n",
       " 21,\n",
       " 519,\n",
       " 862,\n",
       " 267,\n",
       " 1214,\n",
       " 40,\n",
       " 321,\n",
       " 3586,\n",
       " 18,\n",
       " 226,\n",
       " 2,\n",
       " 654,\n",
       " 4,\n",
       " 377,\n",
       " 1449,\n",
       " 914,\n",
       " 71,\n",
       " 266,\n",
       " 1613,\n",
       " 543,\n",
       " 3381,\n",
       " 106,\n",
       " 1428,\n",
       " 608,\n",
       " 2770,\n",
       " 220,\n",
       " 1372,\n",
       " 200,\n",
       " 8,\n",
       " 15,\n",
       " 501,\n",
       " 200,\n",
       " 792,\n",
       " 12,\n",
       " 622,\n",
       " 7,\n",
       " 242,\n",
       " 3,\n",
       " 1336,\n",
       " 178,\n",
       " 112,\n",
       " 15,\n",
       " 298,\n",
       " 857,\n",
       " 967,\n",
       " 589,\n",
       " 730,\n",
       " 3022,\n",
       " 23,\n",
       " 18,\n",
       " 3,\n",
       " 1336,\n",
       " 178,\n",
       " 112,\n",
       " 4,\n",
       " 165,\n",
       " 34,\n",
       " 28,\n",
       " 692,\n",
       " 1472,\n",
       " 1,\n",
       " 124,\n",
       " 246,\n",
       " 1904,\n",
       " 857,\n",
       " 513,\n",
       " 1588,\n",
       " 1753,\n",
       " 90,\n",
       " 20,\n",
       " 1015,\n",
       " 1428,\n",
       " 221,\n",
       " 941,\n",
       " 626,\n",
       " 1249,\n",
       " 18,\n",
       " 1588,\n",
       " 310,\n",
       " 1613,\n",
       " 67,\n",
       " 151,\n",
       " 266,\n",
       " 8,\n",
       " 829,\n",
       " 2801,\n",
       " 15,\n",
       " 441,\n",
       " 1020,\n",
       " 18,\n",
       " 12,\n",
       " 4194,\n",
       " 45,\n",
       " 12,\n",
       " 23,\n",
       " 4,\n",
       " 850,\n",
       " 1325,\n",
       " 914,\n",
       " 142,\n",
       " 4457,\n",
       " 2,\n",
       " 1595,\n",
       " 862,\n",
       " 325,\n",
       " 1175,\n",
       " 349,\n",
       " 881,\n",
       " 667,\n",
       " 18,\n",
       " 1588,\n",
       " 1509,\n",
       " 403,\n",
       " 1005,\n",
       " 2,\n",
       " 2476,\n",
       " 1428,\n",
       " 689,\n",
       " 784,\n",
       " 57,\n",
       " 18,\n",
       " 3558,\n",
       " 99,\n",
       " 117,\n",
       " 914,\n",
       " 75,\n",
       " 411,\n",
       " 142,\n",
       " 1428,\n",
       " 1540,\n",
       " 124,\n",
       " 484,\n",
       " 281,\n",
       " 403,\n",
       " 20,\n",
       " 199,\n",
       " 1309,\n",
       " 200,\n",
       " 792,\n",
       " 1196,\n",
       " 608,\n",
       " 1976,\n",
       " 18,\n",
       " 150,\n",
       " 84,\n",
       " 411,\n",
       " 1369,\n",
       " 443,\n",
       " 3747,\n",
       " 1,\n",
       " 200,\n",
       " 2323,\n",
       " 1414,\n",
       " 1011,\n",
       " 1223,\n",
       " 199,\n",
       " 357,\n",
       " 35,\n",
       " 39,\n",
       " 2324,\n",
       " 2485,\n",
       " 1369,\n",
       " 18,\n",
       " 12,\n",
       " 29,\n",
       " 336,\n",
       " 2014,\n",
       " 12,\n",
       " 4,\n",
       " 96,\n",
       " 1453,\n",
       " 29,\n",
       " 71,\n",
       " 505,\n",
       " 1596,\n",
       " 913,\n",
       " 81,\n",
       " 152,\n",
       " 287,\n",
       " 4,\n",
       " 69,\n",
       " 203,\n",
       " 1,\n",
       " 765,\n",
       " 18,\n",
       " 111,\n",
       " 683,\n",
       " 81,\n",
       " 3382,\n",
       " 1457,\n",
       " 3234,\n",
       " 1748,\n",
       " 190,\n",
       " 353,\n",
       " 249,\n",
       " 37,\n",
       " 12,\n",
       " 4,\n",
       " 914,\n",
       " 310,\n",
       " 1613,\n",
       " 249,\n",
       " 1438,\n",
       " 1089,\n",
       " 86,\n",
       " 3422,\n",
       " 317,\n",
       " 332,\n",
       " 1003,\n",
       " 585,\n",
       " 207,\n",
       " 1428,\n",
       " 1313,\n",
       " 3244,\n",
       " 201,\n",
       " 4,\n",
       " 902,\n",
       " 97,\n",
       " 2062,\n",
       " 4582,\n",
       " 64,\n",
       " 142,\n",
       " 914,\n",
       " 28,\n",
       " 914,\n",
       " 602,\n",
       " 18,\n",
       " 226,\n",
       " 182,\n",
       " 29,\n",
       " 182,\n",
       " 110,\n",
       " 941,\n",
       " 218,\n",
       " 20,\n",
       " 2383,\n",
       " 616,\n",
       " 97,\n",
       " 1189,\n",
       " 566,\n",
       " 48,\n",
       " 1363,\n",
       " 200,\n",
       " 792,\n",
       " 81,\n",
       " 1428,\n",
       " 419,\n",
       " 219,\n",
       " 310,\n",
       " 1613,\n",
       " 67,\n",
       " 218,\n",
       " 50,\n",
       " 602,\n",
       " 4,\n",
       " 1236,\n",
       " 310,\n",
       " 1613,\n",
       " 117,\n",
       " 914,\n",
       " 403,\n",
       " 79,\n",
       " 18,\n",
       " 1588,\n",
       " 99,\n",
       " 75,\n",
       " 411,\n",
       " 765,\n",
       " 3,\n",
       " 112,\n",
       " 349,\n",
       " 4331,\n",
       " 18,\n",
       " 4332,\n",
       " 4625,\n",
       " 608,\n",
       " 914,\n",
       " 124,\n",
       " 123,\n",
       " 312,\n",
       " 246,\n",
       " 1816,\n",
       " 3,\n",
       " 219,\n",
       " 310,\n",
       " 1613,\n",
       " 22,\n",
       " 28,\n",
       " 411,\n",
       " 2383,\n",
       " 914,\n",
       " 417,\n",
       " 140,\n",
       " 75,\n",
       " 444,\n",
       " 534,\n",
       " 3,\n",
       " 1458,\n",
       " 1352,\n",
       " 501,\n",
       " 12,\n",
       " 1481,\n",
       " 55,\n",
       " 174,\n",
       " 4333,\n",
       " 105,\n",
       " 2340,\n",
       " 2232,\n",
       " 914,\n",
       " 65,\n",
       " 82,\n",
       " 62,\n",
       " 203,\n",
       " 4,\n",
       " 154,\n",
       " 505,\n",
       " 2,\n",
       " 377,\n",
       " 25,\n",
       " 1297,\n",
       " 124,\n",
       " 112,\n",
       " 197,\n",
       " 1613,\n",
       " 33,\n",
       " 596,\n",
       " 11,\n",
       " 1236,\n",
       " 1472,\n",
       " 4,\n",
       " 377,\n",
       " 1697,\n",
       " 166,\n",
       " 857,\n",
       " 513,\n",
       " 506,\n",
       " 4,\n",
       " 2,\n",
       " 881,\n",
       " 667,\n",
       " 17,\n",
       " 179,\n",
       " 6,\n",
       " 125,\n",
       " 310,\n",
       " 1613,\n",
       " 203,\n",
       " 1912,\n",
       " 218,\n",
       " 20,\n",
       " 820,\n",
       " 914,\n",
       " 1613,\n",
       " 2,\n",
       " 1002,\n",
       " 71,\n",
       " 4246,\n",
       " 25,\n",
       " 37,\n",
       " 1977,\n",
       " 27,\n",
       " 30,\n",
       " 494,\n",
       " 1215,\n",
       " 1313,\n",
       " 1588,\n",
       " 698,\n",
       " 108,\n",
       " 34,\n",
       " 700,\n",
       " 2,\n",
       " 2375,\n",
       " 719,\n",
       " 532,\n",
       " 3174,\n",
       " 887,\n",
       " 857,\n",
       " 513,\n",
       " 1,\n",
       " 252,\n",
       " 2,\n",
       " 121,\n",
       " 862,\n",
       " 325,\n",
       " 1645,\n",
       " 1882,\n",
       " 152,\n",
       " 349,\n",
       " 2650,\n",
       " 180,\n",
       " 179,\n",
       " 19,\n",
       " 2096,\n",
       " 122,\n",
       " 152,\n",
       " 408,\n",
       " 414,\n",
       " 8,\n",
       " 237,\n",
       " 46,\n",
       " 1072,\n",
       " 633,\n",
       " 111,\n",
       " 2]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_padded=pad_sequences(train_content, maxlen=3215, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([473, 150, 854, ...,   0,   0,   0])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test_set[\"Content\"]=test_set.Content.map(lambda x: remove_URL(x))\n",
    "test_set[\"Content\"]=test_set.Content.map(lambda x: remove_html(x))\n",
    "test_set[\"Content\"]=test_set.Content.map(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_set[\"Content\"]=test_set[\"Content\"].map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_set[\"Content\"]=test_set.Content.map(lambda x: lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content=tokenizer.texts_to_sequences(test_set.Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded=pad_sequences(test_content, maxlen=3215, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.initializers import Constant\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(5000, 32, input_length=3215))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#optimizer=Adam(learning_rate=3e-4)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 3215, 32)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 3212, 32)          4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3212, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1606, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 51392)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               12848250  \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 13,012,629\n",
      "Trainable params: 13,012,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10745 samples, validate on 4605 samples\n",
      "Epoch 1/5\n",
      "10745/10745 [==============================] - 74s 7ms/step - loss: 0.2515 - accuracy: 0.8879 - val_loss: 0.0783 - val_accuracy: 0.9811\n",
      "Epoch 2/5\n",
      "10745/10745 [==============================] - 73s 7ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0400 - val_accuracy: 0.9889\n",
      "Epoch 3/5\n",
      "10745/10745 [==============================] - 73s 7ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0439 - val_accuracy: 0.9868\n",
      "Epoch 4/5\n",
      "10745/10745 [==============================] - 76s 7ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0473 - val_accuracy: 0.9883\n",
      "Epoch 5/5\n",
      "10745/10745 [==============================] - 75s 7ms/step - loss: 5.4579e-04 - accuracy: 0.9999 - val_loss: 0.0447 - val_accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_padded,train_set.Label, epochs=5, validation_data=(test_padded,test_set.Label),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_message=\"Good news, Wuhan's corona virus can be cured by one bowl of freshly boiled garlic water.Old Chinese doctor has proven it's efficacy. Many patients has also proven this to be effective. Eight (8) cloves of chopped garlic add seven (7)cups of water and bring to boil., Eat and drink the boiled garlic water, overnight improvement and healing. Glad to share this.\"\n",
    "\n",
    "test_message=remove_URL(test_message)\n",
    "test_message=remove_html(test_message)\n",
    "test_message=remove_punct(test_message)\n",
    "\n",
    "test_message=remove_stopwords(test_message)\n",
    "test_message=lemmatize(test_message)\n",
    "#Stemming dataset\n",
    "#lamitization\n",
    "test_message=tokenizer.texts_to_sequences(test_message)\n",
    "test_message_padded=pad_sequences(test_message, maxlen=3215, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=model.predict_classes([test_message_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-343bbcddab26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Models\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_model(\"Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-055c15bf3166>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#df = pickle.load(open('TestData.pickle','rb'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#df = df.sample(frac=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdfw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TestData.pickle'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ankus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5268\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5269\u001b[0m         ):\n\u001b[1;32m-> 5270\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5271\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_data'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#df = pickle.load(open('TestData.pickle','rb'))\n",
    "#df = df.sample(frac=1)\n",
    "dfw=pd.DataFrame(pickle.load(open('TestData.pickle','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "#tokenizer = pickle.load(open('TITLETEXTTOKENIZER.pickle','rb'))\n",
    "df3 = pd.read_excel('Final_Test_Dataset_Shuffled.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'label', 'text', 'title'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df3 = df3.sample(frac=1)\n",
    "print(df3.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3['text'].tolist()\n",
    "y_true= df3['label'].tolist()\n",
    "\n",
    "X=remove_URL(X)\n",
    "X=remove_html(X)\n",
    "X=remove_punct(X)\n",
    "X=remove_stopwords(X)\n",
    "\n",
    "X=lemmatize(X)\n",
    "X=tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X,padding = 'post',maxlen= 3215)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322069, 3215)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y_pred = model.predict_classes(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322069"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_df = pd.DataFrame(cm,index = [i for i in ['Real','Fake']],\n",
    "                  columns = [i for i in ['Real','Fake']])\n",
    "plt.figure(figsize = (5,4))\n",
    "sn.heatmap(cm_df, annot=True,fmt='d')\n",
    "plt.show()\n",
    "#print(\"Bruh\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
